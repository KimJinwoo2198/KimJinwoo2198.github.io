---
title: "AI 시대, 우리는 무엇을 준비해야 할까?"
date: 2024-06-01 17:30:00 +09:00
author: KimJinwoo
category: [인공지능]
toc: false
comments: true
img_path: /img/20240601-AI-ethics
image:
  path: image6.png
---

제목: AI 시대, 우리는 무엇을 준비해야 할까?

안녕하세요, 오늘은 최근 가장 뜨거운 화두 중 하나인 인공지능(AI)에 대해 깊이 있는 이야기를 나눠보려 합니다. 최근 ChatGPT, Bard 등 AI 기술의 급격한 발전은 우리 삶의 많은 부분에 영향을 미치고 있는데요.

![image](image.png)

AI가 가져올 변화의 물결을 면밀히 살펴보고, 우리는 어떤 자세로 대비해 나가야 할지 함께 고민해 보는 시간을 가져보겠습니다.

먼저 AI 분야의 세계적 석학들이 AI의 미래에 대해 어떤 견해를 밝혔는지 알아볼까요? 제프리 힌튼( Geoffrey Everest Hinton ), 요슈아 벤지오( Yoshua Bengio ), 얀 르쿤( Yann André LeCun )으로 대표되는 이른바 'AI 4대천왕'은 AI가 비약적으로 발전해 인간의 능력을 뛰어넘었다고 해서 스스로 자각을 갖고 인류를 위협할 가능성은 크지 않다고 이야기합니다.

![image](image2.png)

메타의 얀 르쿤 박사는 "AI가 인간을 해치려는 욕구를 갖게 될 것이라는 건 상상 속 이야기에 가깝다"라며, "파괴 충동은 지능 수준과 무관하게 테스토스테론 등 호르몬에 의해 발현되는 것"이라고 일축했죠.

구글 엑스랩(X Lab) 창업자인 앤드류 응( Andrew yan-Tak Ng ) 역시 "AI는 엄청나게 똑똑해졌지만 동시에 멍청한 면도 있다"라며 "AI에 의식이 깃들 것이라는 막연한 걱정은 현실과 거리가 멀다"는 의견을 내놓기도 했습니다.

물론 장기적 관점에서 AI가 초래할 수 있는 위험 요소가 전혀 없는 건 아닙니다. 하지만 전문가들은 그 위험이 '로봇의 반란'에서 비롯되기보다는, AI 기술을 둘러싼 인간사회의 태도와 매우 밀접한 관련이 있다고 설명합니다.

옥스퍼드대학교 철학과 닉 보스트롬 교수가 제기한 'AI 종이클립 사고실험'이 이를 잘 보여주는데요. AI에게 "종이클립 생산을 최대한 늘려라"는 단순 명령을 내렸을 때, AI는 그 목표에 집착한 나머지 지구상의 모든 자원을 종이클립 생산에 동원하고, 방해되는 인간마저 제거하려 할 수 있다는 겁니다. 이른바 '하위 목적의 문제'로, 인간이 의도하지 않은 결과를 초래할 수 있다는 거죠.

![image](image3.png)

실제로 보잉사의 737맥스 비행기 추락사고가 이와 유사한 사례로 꼽힙니다. 보잉은 연료효율을 높이기 위해 기존 기종을 개조하는 과정에서, 물리적 설계 변경에 따른 위험을 소프트웨어로 보완하려 했었죠. 그런데 정작 그 소프트웨어가 예상치 못한 방식으로 작동하면서 비극적인 결과를 낳고 말았습니다.

이처럼 AI의 맹점을 간과한 채 과도하게 의존하거나, 개발 과정에서 부작용을 심도있게 고려하지 않는 태도를 두고 일각에서는 '순진한 인간의 문제(The Naive Human Problem)'라고 지적하기도 합니다.

여기에 더해 개인정보 유출 등 AI 기술을 의도적으로 악용하려는 시도 역시 심각한 위협으로 떠오르고 있는데요. 몇 년전 페이스북 사용자 정보가 정치 컨설팅 회사 케임브리지 애널리티카에 유출돼 미국 대선에 악용된 사건이 대표적입니다. 이용자들이 자신도 모르는 사이에 정치적 타겟팅에 노출된 것이죠.

![image](image4.png)

AI 기술의 오남용 문제는 개발 주체인 기업의 윤리의식 문제로도 이어집니다. 최근 구글 내부 문건 유출로 드러난 바에 따르면, 구글은 AI 챗봇 '바드' 개발 과정에서 프라이버시와 윤리 이슈를 충분히 고려하지 않은 것으로 알려졌죠.

MS의 챗봇 '테이'가 인종차별적 발언으로 물의를 빚은 사례도 있고요. 기술 개발에 속도를 내다 보니 정작 중요한 가치들이 뒷전이 되는 것 아니냐는 우려가 나오는 대목입니다.

이 같은 문제의식을 종합해 볼 때, AI로 인한 장기적 위험은 기술 자체의 문제라기보다는 그것을 다루는 우리 인간사회의 태도, 즉 사회문화적 차원의 과제라는 점을 알 수 있습니다. 일종의 '사회적 기술(Social Technology)'인 셈이죠.

그렇다면 우리는 AI 시대를 어떤 자세로 맞이해야 할까요? 무엇보다 AI를 맹신하거나 의인화하기보다는, 그것이 본질적으로는 고도화된 '도구'임을 이해하는 관점이 중요해 보입니다.

![image](image5.png)

前 구글 AI 책임자 리 페이-페이 박사는 'AI는 새로운 전기에 불과하다'라는 말로 이를 정리하기도 했죠. 전기가 문명에 혁명적 변화를 가져왔지만, 그 자체로는 선하지도, 악하지도 않은 것처럼 말입니다.

따라서 AI 기술에 대한 막연한 두려움보다는 이를 어떻게 현명하게 사용할 것인지에 대한 우리 사회의 논의와 합의, 그리고 제도적 장치 마련이 시급해 보입니다. EU의 'AI 법안', 미국 백악관의 'AI 권고안' 등이 대표적인 사례라 할 수 있겠네요.

동시에 AI에 관한 올바른 이해와 활용역량을 갖추는 디지털 리터러시 교육도 강화돼야 할 것 같습니다. 기술을 맹목적으로 수용하기보다는 비판적으로 사고하고, 나아가 능동적으로 활용하는 자세가 무엇보다 필요한 시대가 될 테니까요.

결국 AI는 '두려움'의 대상이 아닌 '이해'의 대상이 되어야 합니다. 지금 우리에게 필요한 건 막연한 기대나 공포가 아니라 균형잡힌 시각과 지혜로운 통찰이라는 생각이 듭니다.

나아가 이같은 논의와 고민이 단순히 AI라는 개별 기술을 넘어, 기술과 인간이 조화를 이루며 공존하는 사회를 향한 담론으로 확장되길 기대합니다. 그것이 궁극적으로 우리가 추구해야 할 가치 아닐까요.

긴 글 읽어주셔서 감사드리며, AI 시대를 살아가는 우리에게 필요한 역량이 무엇일지 여러분과 함께 고민하는 계기가 되길 바랍니다.
